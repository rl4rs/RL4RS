---
layout: page
title: Speakers
permalink: /speakers/
---

<style>
.speaker-table {
    border: none;
    margin: 20px 0;
    width: 100%;
}

.speaker-table td {
    padding: 20px;
    vertical-align: top;
}

.speaker-image {
    width: 200px;
    height: 200px;
    object-fit: cover;
    border-radius: 8px;
    box-shadow: 0 2px 5px rgba(0,0,0,0.1);
}

.speaker-bio {
    font-size: 16px;
    line-height: 1.6;
    padding-left: 30px;
}
.speaker-list {
    list-style-type: none;
    padding: 0;
    margin: 0;
}
</style>

<ul class="speaker-list">
  <li>
    <table class="speaker-table">
      <tr>
        <td style="width: 200px;">
          <img src="https://github.com/hnekoeiq/RL4RS/blob/main/assets/images/pierre-Luc_Bacon.jpeg?raw=true" 
               alt="Pierre-Luc Bacon" 
               class="speaker-image"/>
        </td>
        <td class="speaker-bio">
          <p><b>Pierre-Luc Bacon</b>: is an Assistant Professor at the University of Montreal's DIRO, a CIFAR AI Chair, a core member of Mila, and affiliated with the Institute for Data Valorization (IVADO). Their research lies at the intersection of theory and application in reinforcement learning, focusing on real-world problems such as HVAC systems and molecular modeling. They work on improving RL through representation learning, neural differential equations, and transformer-based models, with a particular interest in addressing the curse of horizon in long-term planning. Recently, they have been exploring ways to leverage large language models to tackle specification challenges in RL, aiming to make RL systems more aligned and sample-efficient in practice.</p>
        </td>
      </tr>
    </table>
  </li>
  <li>
    <table class="speaker-table">
      <tr>
        <td style="width: 400px;">
          <img src="https://github.com/hnekoeiq/RL4RS/blob/main/assets/images/Martin_Riedmiller.png?raw=true" 
               alt="Martin Riedmiller" 
               class="speaker-image"/>
        </td>
        <td class="speaker-bio">
          <p><b>Martin Riedmiller</b>: is a research director and lead of the Controls team at Google DeepMind, previously serving as a university professor for machine learning and neuroinformatics from 2002 to 2015. His core scientific interest lies in intelligent machines that autonomously learn from scratch, particularly neural networks and their information storage and generalization capabilities. This fascination began with his master thesis on 'Rprop' (1992) and continued through pioneering work spanning neural forecasting for finance, self-driving vehicles, and brain-computer interfaces. His Brainstormers robotic soccer team won the RoboCup World Championship five times while pioneering reinforcement learning, and his algorithms including Neural Fitted Q Iteration and Deep Fitted Q established foundations for modern AI research. His career journey has included roles as a game programmer (1981-1986), computer science professor at German universities, co-founder of an early AI startup, before joining DeepMind in 2015.</p>
        </td>
      </tr>
    </table>
  </li>
  <li>
    <table class="speaker-table">
      <tr>
        <td style="width: 400px;">
          <img src="https://github.com/hnekoeiq/RL4RS/blob/main/assets/images/martha_white.jpg?raw=true" 
               alt="Martha White" 
               class="speaker-image"/>
        </td>
        <td class="speaker-bio">
          <p><b>Martha White</b>: is an Associate Professor of Computing Science at the University of Alberta and a Fellow of Amii, which is one of the top machine learning centres in the world. She holds a Canada CIFAR AI Chair, a Tier 2 Canada Research Chair in Reinforcement Learning and received IEEE's "AIs 10 to Watch: The Future of AI" award in 2020. She has authored more than 70 papers in top journals and conferences. Martha is an associate editor for JMLR and TMLR, has served as co-program chair for ICLR and for RLC and regularly serves as an area chair for top AI conferences. Her research focus is on developing algorithms that learn to adapt continually, with a focus on more sustainable systems.</p>
        </td>
      </tr>
    </table>
  </li>
  <li>
    <table class="speaker-table">
      <tr>
        <td style="width: 400px;">
          <img src="https://github.com/hnekoeiq/RL4RS/blob/main/assets/images/Akhil_Bagaria.jpeg?raw=true" 
               alt="Akhil Bagaria" 
               class="speaker-image"/>
        </td>
        <td class="speaker-bio">
          <p><b>Akhil Bagaria</b>: is a Research Scientist at Amazon, focusing on Reinforcement Learning applications for the Amazon Supply Chain. Previously, he completed his Computer Science PhD at Brown University under George Konidaris in the Intelligent Robot Lab and Brown BigAI initiative, including a summer internship with David Silver's RL team at DeepMind in 2022. His research centers on creating general-purpose agents that can learn from raw sensorimotor data, with particular emphasis on exploration and skill discovery problems. Before his doctoral studies, Akhil graduated from Harvey Mudd College in 2016, where he worked in the Lab for Autonomous and Intelligent Robotics under Professor Chris Clark. His professional experience also includes two years at Apple in Cupertino as part of the Multitouch Algorithms team, where he worked under the guidance of Nicole Wells and Wayne Westerman.</p>
        </td>
      </tr>
    </table>
  </li>
  <li>
    <table class="speaker-table">
      <tr>
        <td style="width: 400px;">
          <img src="https://github.com/hnekoeiq/RL4RS/blob/main/assets/images/Jorge_Montalvo_Arvizu.jpeg?raw=true" 
               alt="Jorge Montalvo" 
               class="speaker-image"/>
        </td>
        <td class="speaker-bio">
          <p><b>Jorge Montalvo</b>: is a Senior Research Scientist at Amazon, leading the Personalization Science team for Amazon's Supply Chain Optimization Technologies (SCOT) organization. His research focuses on developing reinforcement learning algorithms and optimization methods for large scale supply chain problems. Prior to joining Amazon, Jorge obtained his PhD in Operations Research from Columbia University, where he worked on theoretical and computational aspects of optimization under uncertainty.</p>
        </td>
      </tr>
    </table>
  </li>
</ul>